{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05b448b-326c-4ff0-9b06-39c15602a86d",
   "metadata": {},
   "source": [
    "# Leveraging large language models and vector databases for exploring life cycle inventory databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6f2a5-e62d-424e-b944-0a326c04c7e7",
   "metadata": {},
   "source": [
    "## ChatGPT\n",
    "\n",
    "Let's run a simple query.\n",
    "For that, open [OpenAI Chat](https://chat.openai.com/), sign up/sign in, and create a new chat (it's free)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c95973-62ca-4ecb-94c6-fa6dc53266ac",
   "metadata": {},
   "source": [
    "![ChatGPT: What is Ecoinvent?](chatgpt-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043dea2-ecea-4ae6-a4ca-cdc1f88bd4d6",
   "metadata": {},
   "source": [
    "ChatGPT knows about Ecoinvent, great! The answer seems pretty satisfactory. Let's continue the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd47ba-52eb-46d1-99c7-369041592e6d",
   "metadata": {},
   "source": [
    "![ChatGPT: Cool, where is it located?](chatgpt-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363cd17-7ecf-44e7-add1-66beb187785f",
   "metadata": {},
   "source": [
    "### What is special about this query?\n",
    "\n",
    "<details>\n",
    "  \n",
    "<summary><b>Answer</b></summary>\n",
    "This seems stateful, as if ChatGPT keeps a session of my conversation, as I used \"it\".\n",
    "The context must be shomehow saved.\n",
    "\r\n",
    "</details>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7e2a4-76c4-427b-b38e-fddca1e9378d",
   "metadata": {},
   "source": [
    "### Now, how popular is Brightcon?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71796f4-bf3e-4152-bca8-2c3b73e5ebcc",
   "metadata": {},
   "source": [
    "![ChatGPT: what is Brightcon?](chatgpt-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ee7d8-a3bb-4a0c-94f3-aa876388b6a9",
   "metadata": {},
   "source": [
    "Sadly, it does not know. A first question then comes to mind:\n",
    "\n",
    "### How do we teach ChatGPT / LLMs in general new knowledge? How would you do it with a \"traditional ML model\"?\n",
    "\n",
    "<details>\n",
    "  \n",
    "<summary><b>Answer</b></summary>\n",
    "<b>Fine-tuning</b>. Take the model and train on top of it.\n",
    "\n",
    "But as of only very recently, ChatGPT offers fine-tuning capability. Regardless, this is quite hard and not the first solution that should come to mind.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83c62c-91fb-404c-b3bd-89e5a18f44c9",
   "metadata": {},
   "source": [
    "### Let's feed ChatGPT with a little extra information\n",
    "\n",
    "We do a quick Google search for recent LCA conferences, paste a few summaries in the prompt, and try again\n",
    "\n",
    "![ChatGPT: now with context, what is Brightcon?](chatgpt-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de4ef13-8ba5-471f-aee5-bb906e3e4936",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "- LLMs can generate high-quality human-language answers, based on human-language input\n",
    "- LLMs can be passed context at runtime, that they can use in their responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e30ded-fc4e-4925-81e7-e17416c3ca42",
   "metadata": {},
   "source": [
    "## Moving to the API\n",
    "\n",
    "Let's replicate the previous flows with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a81b50-a803-499c-8e10-267d6a9c1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b238fde-7850-42f0-a780-cbaca7fc0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-80D7zOhuJZzS5qBEUI2tknSm13GA4 at 0x7f5b185d0ef0> JSON: {\n",
       "  \"id\": \"chatcmpl-80D7zOhuJZzS5qBEUI2tknSm13GA4\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695061155,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Ecoinvent is a database that provides life cycle inventory (LCI) data for various materials and processes. It is one of the most widely used LCI databases in the world and includes comprehensive data on energy, resource use, emissions, and other environmental impacts associated with the production of goods and services. Researchers, companies, and policymakers use Ecoinvent to assess and compare the environmental performance of products, inform sustainability assessments, and support decision-making processes. It helps users understand the environmental implications of their activities and enables them to make more informed and sustainable choices.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 23,\n",
       "    \"completion_tokens\": 112,\n",
       "    \"total_tokens\": 135\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Ecoinvent?\"}\n",
    "    ]\n",
    ")\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db084b33-3407-47b4-b6cd-967dc7d619df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-80D8rPcECNL8iQdiUHY05RMTQr9In at 0x7f5b181c8ef0> JSON: {\n",
       "  \"id\": \"chatcmpl-80D8rPcECNL8iQdiUHY05RMTQr9In\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695061209,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Ecoinvent is located in Switzerland. It is managed by the Swiss Centre for Life Cycle Inventories, a non-profit organization based in Zurich. The database is continuously updated and maintained by a team of experts who collect data from various sources, verify and validate it, and ensure its accuracy and relevance. Ecoinvent has gained international recognition and is widely used by researchers, companies, and organizations around the world for life cycle assessment (LCA) studies and environmental impact evaluations.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 148,\n",
       "    \"completion_tokens\": 95,\n",
       "    \"total_tokens\": 243\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Ecoinvent?\"},\n",
    "        {\"role\": \"assistant\", \"content\": response1[\"choices\"][0][\"message\"][\"content\"]},\n",
    "        {\"role\": \"user\", \"content\": \"Where is it located?\"}\n",
    "    ]\n",
    ")\n",
    "response2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e344b0-6af7-4423-9fae-bf4ba4971976",
   "metadata": {},
   "source": [
    "### Breaking down the response\n",
    "\n",
    "```javascript\n",
    "{\n",
    "    \"usage\": {\n",
    "    \"prompt_tokens\": 148,\n",
    "    \"completion_tokens\": 95,\n",
    "    \"total_tokens\": 243\n",
    "}\n",
    "```\n",
    "\n",
    "What are these **tokens**?\n",
    "\n",
    "OpenAI provides a [nice web app OpenAI Tokenizer](https://platform.openai.com/tokenizer) to understand how words are broken down into tokens.\n",
    "\n",
    "They say\n",
    "\n",
    "```\n",
    "A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly Â¾ of a word (so 100 tokens ~= 75 words).\n",
    "`````\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47688ff3-6839-4167-b0ce-1e8f12840ecc",
   "metadata": {},
   "source": [
    "![Tokenizer words](tokenizer-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c3f293-b730-4a31-b9ec-c14e61dd2573",
   "metadata": {},
   "source": [
    "### Tokens are mappings for sequences of letters to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23902be9-0439-4b5d-8769-5ba093c15e7d",
   "metadata": {},
   "source": [
    "![Tokenizer words](tokenizer-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f624467-e040-4f5c-8640-2dcd47fe0592",
   "metadata": {},
   "source": [
    "### And programmatically with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22e100e0-d613-40be-9d5a-3c3e2acd53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d915b6-61e4-4947-8382-62ca37c46cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3923, 374, 469, 7307, 688, 30]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = enc.encode(\"What is Ecoinvent?\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419f6316-b08d-4472-b66e-b4fc841835bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', ' is', ' E', 'coin', 'vent', '?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[enc.decode([token]) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7f2a2-16ac-45e7-b593-b9c8fe569915",
   "metadata": {},
   "source": [
    "### Why do we care about tokens here?\n",
    "\n",
    "<details>\n",
    "  \n",
    "<summary><b>Answer</b></summary>\n",
    "Because there is a limit to the size of the context window, and it is measured in tokens.\n",
    "Also, the pricing is per token.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2f121-f3cc-4f39-9e94-f650f8c79b1c",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "- Text is chunked into tokens before being manipulated. Tokens are just mappings from strings to integers. They define an exhaustive vocabulary.\n",
    "- There is a context window, we can't pass an unlimited amount of data to LLMS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2dace-7074-4baf-b9a2-ba1c3eb217e8",
   "metadata": {},
   "source": [
    "## Which applications can you think of? In the context of LCAs\n",
    "\n",
    "Here is one I used for Brightcon:\n",
    "\n",
    "- Text generation from a small description\n",
    "\n",
    "<details>\n",
    "  \n",
    "<summary><b>Answer</b></summary>\n",
    "\n",
    "Let's describe the process of doing an LCA:\n",
    "\n",
    "1. Collect imperfect data from a customer - for instance a bunch of Excel files with random names for units (seen at the Hackathon): `kg CH4`, `PCS`. <b>Covered application 1: \"kg CH4\" -> \"kg\" and \"PCS\" -> \"Item(s)\"</b>\n",
    "2. Create a supply chain in an LCA software, mapping this \"company data\" to LCI data (like Ecoinvent, but we'll use ELCD here).\n",
    "3. Pick from the numerous processes in the LCI database the one that matches the closest your data (or refine this simplified approach). <b>Covered application 2: Search and match</b>\n",
    "4. Compute impacts and do something with them\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33291ea3-1754-4e4d-ac01-7e9719bab989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
