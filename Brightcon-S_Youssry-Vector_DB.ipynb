{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22074692",
   "metadata": {},
   "source": [
    "# Leveraging large language models and vector databases for exploring life cycle inventory databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76a530",
   "metadata": {},
   "source": [
    "Life Cycle Assessment (LCA) has emerged as a vital tool for evaluating the environmental impacts of products and processes throughout their entire life cycle. To conduct comprehensive LCAs, reliable and extensive Life Cycle Inventory Databases (LCID) are essential. However, accessing, interpreting, and utilizing such databases can be challenging due to their sheer size and complexity. This conference presentation proposes an innovative approach that harnesses the power of Large Language Models (LLMs) and vector databases to effectively explore and navigate LCID, specifically focusing on the European Life Cycle Database (ELCD) in the OpenLCA format.\n",
    "\n",
    "In recent years, LLMs have achieved significant advancements in natural language processing, enabling them to comprehend complex queries and deliver contextually relevant information. Leveraging the capabilities of LLMs, particularly exemplified by the ChatGPT model, allows for intuitive interactions with LCID, facilitating user access and comprehension of extensive LCA data.\n",
    "\n",
    "Furthermore, to enhance the performance and efficiency of LCA-related tasks, this study introduces vector databases designed to store and manage LCA-specific data structures. The use of vector databases complements the traditional relational databases typically employed for LCID, offering optimized search operations, lower latency, and improved scalability.\n",
    "\n",
    "The conference presentation will highlight a case study involving ChatGPT and vector databases, which showcases their collective potential to extract relevant information from the ELCD in OpenLCA format. Through a series of real-world scenarios, the feasibility and efficacy of this approach will be demonstrated, illustrating how LLMs can efficiently respond to LCA queries while vector databases efficiently store and retrieve vast amounts of LCA data.\n",
    "\n",
    "Attendees will gain insights into the benefits of incorporating cutting-edge technology into the LCA domain, fostering better-informed decision-making processes across diverse industries. The proposed methodology not only addresses the challenges of accessing and comprehending complex LCID but also opens new avenues for advancing LCA research and environmental sustainability assessments.\n",
    "\n",
    "In conclusion, this conference presentation will empower LCA practitioners, researchers, and stakeholders to harness the power of LLMs and vector databases, ultimately unlocking the full potential of Life Cycle Inventory Databases for more comprehensive and insightful life cycle assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a85577",
   "metadata": {},
   "source": [
    "## Requirements to run this notebook\n",
    "\n",
    "See this [brightcon-2023-llm Github repo](https://github.com/sapiologie/brightcon-2023-llm) for instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80602916",
   "metadata": {},
   "source": [
    "## Plan (1 min)\n",
    "\n",
    "**1. Introduction to LLMs, embeddings, and the applications covered here**\n",
    "\n",
    "- I/O diagram of how a LLM works\n",
    "  - Context window\n",
    "  - Tokens and embeddings\n",
    "  - It's just text in text out\n",
    "- Internal representation of text - vector embeddings\n",
    "  - Example of Word2vec\n",
    "  - Access ChatGPT embeddings\n",
    "- Applications\n",
    "  - Vector (~ semantic) search (covered)\n",
    "  - Question answering (covered)\n",
    "  - Summarization\n",
    "\n",
    "**2. Search**\n",
    "\n",
    "- The dataset: ELCD\n",
    "- Traditional keyword based search\n",
    "- Evolution: text distance\n",
    "- Moving to vector search with ChromaDB\n",
    "- Advanced search mechanisms (show Langchain flows and \"hybrid search\")\n",
    "\n",
    "**3. Question answering**\n",
    "\n",
    "- Example of trucks: finding the payload\n",
    "- Prompt engineering with JSON output parsing\n",
    "- Going further: an actual schema with Pydantic\n",
    "\n",
    "**4. Langchain**\n",
    "\n",
    "- Rewriting 2. and 3. with Langchain\n",
    "- Exploring this framework\n",
    "- Criticisms\n",
    "\n",
    "**5. Resources**\n",
    "\n",
    "- List of resources\n",
    "- Takeaway: human/machine boundary, don't diss traditional NLP, see this as a tool in your traditional engineering system instead of a magic wand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250b714",
   "metadata": {},
   "source": [
    "## 1. Introduction to LLMs, embeddings, and the applications covered here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cde103",
   "metadata": {},
   "source": [
    "### 1.1 LLM internals (1 min)\n",
    "\n",
    "```\n",
    "Input text (maximum context window)\n",
    "-> Tokenization\n",
    "-> Embeddings\n",
    "-> LLM\n",
    "-> Embeddings\n",
    "-> To text\n",
    "```\n",
    "\n",
    "ChatGPT flow\n",
    "- Write **text input**\n",
    "- Transformed into a series of **tokens**: integer representation of a word through Byte Pair Encoding\n",
    "  - GPT3 vocabulary, about 50k tokens\n",
    "  - Source: [OpenAI Tokenizer web app](https://platform.openai.com/tokenizer) and [Tiktoken Python library](https://github.com/openai/tiktoken)\n",
    "\n",
    "- The ChatGPT model: \"GPT-3.5 is a transformer trained as a completion-style model, which means that if we give it a few words as input, it's capable of generating a few more words that are likely to follow them in the training data.\"\n",
    "  - Send text input in, transformed to tokens (within the context window of 4097 tokens), passed through the model, **returns a series of tokens, decoded into text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155c8957-dddf-4462-a6bb-caddb86226a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_lorry_process_uuids = [\n",
    "    \"b444f4d0-3393-11dd-bd11-0800200c9a66\",\n",
    "    \"b444f4d1-3393-11dd-bd11-0800200c9a66\",\n",
    "    \"b444f4d2-3393-11dd-bd11-0800200c9a66\",\n",
    "    \"b444f4d3-3393-11dd-bd11-0800200c9a66\",\n",
    "    \"b444f4d4-3393-11dd-bd11-0800200c9a66\",\n",
    "    \"b4451be0-3393-11dd-bd11-0800200c9a66\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b326d148-5375-4023-a04a-ebbe71558b5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Introductory concept 2 - ChatGPT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Tokens in -> Tokens out\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho won the world series in 2020?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe Los Angeles Dodgers won the World Series in 2020.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhere was it played?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m response\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/brightcon-1mp8TyWu-py3.11/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/brightcon-1mp8TyWu-py3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[1;32m    141\u001b[0m         timeout,\n\u001b[1;32m    142\u001b[0m         stream,\n\u001b[1;32m    143\u001b[0m         headers,\n\u001b[1;32m    144\u001b[0m         request_timeout,\n\u001b[1;32m    145\u001b[0m         typed_api_type,\n\u001b[1;32m    146\u001b[0m         requestor,\n\u001b[1;32m    147\u001b[0m         url,\n\u001b[1;32m    148\u001b[0m         params,\n\u001b[0;32m--> 149\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__prepare_create_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/brightcon-1mp8TyWu-py3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 106\u001b[0m requestor \u001b[38;5;241m=\u001b[39m \u001b[43mapi_requestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIRequestor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    115\u001b[0m     deployment_id,\n\u001b[1;32m    116\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m     params,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/brightcon-1mp8TyWu-py3.11/lib/python3.11/site-packages/openai/api_requestor.py:138\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     organization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    136\u001b[0m ):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_base \u001b[38;5;241m=\u001b[39m api_base \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_base\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m         ApiType\u001b[38;5;241m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m ApiType\u001b[38;5;241m.\u001b[39mfrom_str(openai\u001b[38;5;241m.\u001b[39mapi_type)\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_version \u001b[38;5;241m=\u001b[39m api_version \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_version\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/brightcon-1mp8TyWu-py3.11/lib/python3.11/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo API key provided. You can set your API key in code using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key = <API-KEY>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key_path = <PATH>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "# Introductory concept 2 - ChatGPT\n",
    "# Tokens in -> Tokens out\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a502596f-39d9-4e02-bf0a-55531d4b4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introductory concept 1 - Tokens\n",
    "# Useful for a context window and output size\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5f8e68-aa42-4e9d-b4e4-fa850b9fba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 1917, 11, 856, 836, 374, 24082, 318]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = enc.encode(\"hello world, my name is Selim\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5720088a-02aa-4538-86ee-28dc455ff374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15339: hello\n",
      "1917:  world\n",
      "11: ,\n",
      "856:  my\n",
      "836:  name\n",
      "374:  is\n",
      "24082:  Sel\n",
      "318: im\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    dec = enc.decode([token])\n",
    "    print(f\"{token}: {dec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90eed21-da13-43be-9bbf-a25c4a0ab900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7zArIUmyYkuiH13tDO7I7wM5S5855 at 0x7f6a002304d0> JSON: {\n",
       "  \"id\": \"chatcmpl-7zArIUmyYkuiH13tDO7I7wM5S5855\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1694814104,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The World Series in 2020 was played at Globe Life Field in Arlington, Texas.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 53,\n",
       "    \"completion_tokens\": 18,\n",
       "    \"total_tokens\": 71\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c559f3-8334-4a8f-a7e4-ba9a16248757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The World Series in 2020 was played at Globe Life Field in Arlington, Texas.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dede43b-9204-46be-b4ad-d904854c9eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(enc\u001b[38;5;241m.\u001b[39mencode(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "len(enc.encode(response['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "747b1788-f8d6-4afb-854a-5c4decf249df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7zBIr8cHE45Lu75c3rPlaIX0NoWKH at 0x7f69e7f8bef0> JSON: {\n",
       "  \"id\": \"chatcmpl-7zBIr8cHE45Lu75c3rPlaIX0NoWKH\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1694815813,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The distance between Paris and Esch-sur-Alzette is approximately 365 kilometers (227 miles) by road.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 31,\n",
       "    \"completion_tokens\": 23,\n",
       "    \"total_tokens\": 54\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applications - 1 - Question answering\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the distance between Paris and Esch-sur-Alzette?\"},\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "567a955b-9414-4561-92a6-94ac102a9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_mix_desc = \"\"\"\n",
    "The Italian electricity consumption mix is provided by multiple energy carriers.\n",
    "The Italian specific mix is shown in the pie chart \"Power Grid Mix - IT\".\n",
    "The electricity is either produced in energy carrier specific power plants and / or energy carrier specific heat and power plants (CHP).\n",
    "The Italian specific fuel supply (share of resources used, by import and / or domestic supply) including the Italian specific energy carrier properties (e.g. element and energy contents) are accounted for.\n",
    "Furthermore Italian specific technology standards of power plants regarding efficiency, firing technology, flue-gas desulphurisation, NOx removal and dedusting are considered.\n",
    "The Italian electricity consumption mix is modelled as shown in the flow diagram \"Modelling of Power Consumption Mix\".\n",
    "It includes imported/exported electricity, distribution losses (in %) and the own use by energy producers.\n",
    "The data set considers the whole supply chain of the fuels from exploration over extraction and preparation to transport of fuels to the power plants.\n",
    "The background system is addressed as follows:  Transports: All relevant and known transport processes used are included.\n",
    "Overseas transports including rail and truck transport to and from major ports for imported bulk resources are included.\n",
    "Furthermore all relevant and known pipeline and / or tanker transport of gases and oil imports are included.\n",
    "Energy carriers: Coal, crude oil, natural gas and uranium are modelled according to the specific import situation.\n",
    "Refinery products: Diesel, gasoline, technical gases, fuel oils, basic oils and residues such as bitumen are modelled via a country-specific, refinery parameterized model.\n",
    "The refinery model represents the current national standard in refinery techniques (e.g. emission level, internal energy consumption,...) as well as the individual country-specific product output spectrum, which can be quite different from country to country.\n",
    "Hence the refinery products used show the individual country-specific use of resources. The supply of crude oil is modelled, again, according to the country-specific crude oil situation with the respective properties of the resources.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c77cd8de-3e78-43ef-82de-426151190842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7zBKEEY3Co8Cm9APq6Yzt8LoPIHCt at 0x7f69e7fd3cb0> JSON: {\n",
       "  \"id\": \"chatcmpl-7zBKEEY3Co8Cm9APq6Yzt8LoPIHCt\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1694815898,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The two key elements of the content between the backticks are: \\n1. The description of the Italian electricity consumption mix, including the energy carriers, power plants, and heat and power plants used for electricity production in Italy. It also mentions the fuel supply and import/export situation, as well as the technology standards of power plants in Italy.\\n2. The modeling of the Italian electricity consumption mix, which takes into account factors such as imported/exported electricity, distribution losses, and the self-consumption by energy producers. It also considers the entire supply chain of fuels, including exploration, extraction, preparation, and transportation to power plants. The background system addresses relevant transport processes and the specific import situation for energy carriers and refinery products.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 443,\n",
       "    \"completion_tokens\": 146,\n",
       "    \"total_tokens\": 589\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applications - 2 - Summarization\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        ```\n",
    "        {italian_mix_desc}\n",
    "        ```\n",
    "    \n",
    "        Summarize the 2 key elements of the content between the backticks.\n",
    "        \"\"\"},\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7aec0d82-05d7-4965-bc69-51a196e8811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 143 to 146 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696564a1",
   "metadata": {},
   "source": [
    "### 1.2 Embeddings (1 min)\n",
    "\n",
    "- Then lists of tokens are mapped to **embeddings**: a vector representation of tokens. The latest OpenAI model is \"text-embedding-ada-002\"\n",
    "  - Dimension: 1536\n",
    "  - This is a full machine learning model\n",
    "  - It has a context size of \"8192\" tokens\n",
    "  - Output of 1.5k tokens\n",
    "  - 1 token = 4 characters in English OR 100 tokens = 75 words\n",
    "  - [Ada 2 annoucement](https://openai.com/blog/new-and-improved-embedding-model)\n",
    "  - [How they work](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)\n",
    "\n",
    "\n",
    "Show an example and the code for **\"What is life cycle assessment?\"**ar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f00bd9-cb64-453b-9c8b-f7ed4558812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015214473940432072, 0.0019709658809006214, 0.0004404623177833855, -0.02267022430896759, -0.01617608033120632, -0.0011270894901826978, -0.011782984249293804, 0.010432781651616096, -0.019785402342677116, -0.019047731533646584]...\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "response = openai.Embedding.create(\n",
    "    input=\"What is life cycle assessment?\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "embeddings = response['data'][0]['embedding']\n",
    "print(f\"{embeddings[:10]}...\")\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b20bcccc-8191-4e86-b850-2bd3623e2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = \"Cotton production\"\n",
    "a2 = \"Nuclear energy\"\n",
    "query = \"Find an activity to power my car\"\n",
    "\n",
    "embed_a1 = openai.Embedding.create(input=a1, model=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
    "embed_a2 = openai.Embedding.create(input=a2, model=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
    "embed_query = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f2b507f-d769-409a-8043-617c29310708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bf7aede-8c37-413d-80c0-e906edaeada3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777373690392992"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embed_a1, embed_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8026f70b-164a-4b58-ae0d-40c13a2a43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist 1=0.7156581197365439 / dist 2=0.785766316483196\n"
     ]
    }
   ],
   "source": [
    "sim_a1_q = cosine_similarity(embed_a1, embed_query)\n",
    "sim_a2_q = cosine_similarity(embed_a2, embed_query)\n",
    "print(f\"dist 1={sim_a1_q} / dist 2={sim_a2_q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a0c81a-eadd-43de-82eb-0a4a6d59aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist 1=0.8757795762923071 / dist 2=0.7661570944163845\n"
     ]
    }
   ],
   "source": [
    "query_2 = \"Making of material for textile\"\n",
    "embed_query_2 = openai.Embedding.create(input=query_2, model=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
    "\n",
    "sim_a1_q2 = cosine_similarity(embed_a1, embed_query_2)\n",
    "sim_a2_q2 = cosine_similarity(embed_a2, embed_query_2)\n",
    "print(f\"dist 1={sim_a1_q2} / dist 2={sim_a2_q2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f0509",
   "metadata": {},
   "source": [
    "## 2. Search (1 min)\n",
    "\n",
    "ELCD : TODO description\n",
    "- Number of activities: N\n",
    "- Number of elementary flows: K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170b7c4",
   "metadata": {},
   "source": [
    "### 2.1 Keyword-based search (1 min)\n",
    "\n",
    "TODO put the activities in a Pandas DataFrame and do keyword search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949b30b",
   "metadata": {},
   "source": [
    "### 2.2. Inexact search (1 min)\n",
    "\n",
    "TODO Pandas DataFrame with a text distance function and an inexact query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f55bf",
   "metadata": {},
   "source": [
    "### 2.3 Vector search (8 min)\n",
    "\n",
    "TODO Introduce and instanciate ChromaDB\n",
    "\n",
    "TODO Show how to get one embedding from OpenAI\n",
    "\n",
    "TODO Show I've saved them in a JSON format\n",
    "\n",
    "TODO Talk about the pricing (cost me pennies)\n",
    "\n",
    "TODO Ingest all JSON files into ChromaDB\n",
    "\n",
    "TODO Show examples of search in English and French\n",
    "\n",
    "TODO Advanced search mechanisms - Langchain flows\n",
    "\n",
    "TODO Advanced search - Hybrid search Vector + keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f91da",
   "metadata": {},
   "source": [
    "## 3. Question answering (5 min)\n",
    "\n",
    "TODO Get 3 example datasets from ELCD about trucks and show their description here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd209584",
   "metadata": {},
   "source": [
    "### 3.1 Simple text output (3 min)\n",
    "\n",
    "TODO Ask questions to get the payload in a text format and show the output using OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ca690",
   "metadata": {},
   "source": [
    "### 3.2 Prompt engineering (5 min)\n",
    "\n",
    "TODO Define it\n",
    "\n",
    "TODO Simple and manual JSON output parsing (describe JSON in the input).\n",
    "\n",
    "TODO Parse the JSON with a regex (get the Regex with ChatGPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790147ed",
   "metadata": {},
   "source": [
    "### 3.3 Pydantic schemas (5 min)\n",
    "\n",
    "TODO Define a Pydantic schema\n",
    "\n",
    "TODO Describe this schema in the input\n",
    "\n",
    "TODO Parse and validate the schema in the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452961d",
   "metadata": {},
   "source": [
    "## 4. Langchain (2 min)\n",
    "\n",
    "TODO Explain what it is.\n",
    "\n",
    "TODO Show the tutorials from Deeplearning.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2510f6e",
   "metadata": {},
   "source": [
    "### 4.1. Search with Langchain and ChromaDB (2 min)\n",
    "\n",
    "TODO Walk through the example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fe57f",
   "metadata": {},
   "source": [
    "### 4.2. JSON output parsing with Langchain (2 min)\n",
    "\n",
    "TODO Show Pydantic output parser chain\n",
    "\n",
    "TODO Show another example to parse \"units\" field from an imperfect CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bc15b",
   "metadata": {},
   "source": [
    "### 4.3. Quick peak at the framework (2 min)\n",
    "\n",
    "TODO Show main applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5cf7cb",
   "metadata": {},
   "source": [
    "### 4.4. Criticisms (1 min)\n",
    "\n",
    "Open-source but feels opaque as it becomes bloated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42cf11",
   "metadata": {},
   "source": [
    "## 5. Resources (2 min)\n",
    "\n",
    "https://public.3.basecamp.com/p/RUgMdhPpg72dPP5Y5MNDMXHm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64767e19",
   "metadata": {},
   "source": [
    "### 6. Conclusion (1 min)\n",
    "\n",
    "- Very useful as a human to machine correcter\n",
    "- Try to understand the concepts, there are not that many, then plug and play bits to your application\n",
    "- Good framework to think about it: build your application with your usual engineering best practices, identify bottlenecks that could be solved by AI. Do not start by trying to squeeze AI wherever. For instance, regexes are very powerful at information extraction, so don't ditch it for LLMs right away.\n",
    "- Hard to stay on track, Hacker News, AlphaSignal, the Langchain newsletter are good sources of up to date information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
